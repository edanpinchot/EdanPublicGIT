# -*- coding: utf-8 -*-
"""RestaurantKerasRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_eiHkiBytwXv-otOTupmxfdYmlJSl_qO
"""

import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense
from keras.wrappers.scikit_learn import KerasRegressor
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

from google.colab import files
uploaded = files.upload()

import io
import tensorflow as tf

train = pd.read_csv(io.BytesIO(uploaded['train.csv']))
train_x = pd.DataFrame(train)
train_y = train_x.pop("revenue")

print(train_x)

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder
label_encoder = LabelEncoder()

train_x[["day", "month", "year"]] = train_x["Open Date"].str.split("/", expand = True)
train_x.pop("Open Date")

cityGroupEncoded = label_encoder.fit_transform(train_x["City Group"])
typeEncoded = label_encoder.fit_transform(train_x["Type"])
cityEncoded = label_encoder.fit_transform(train_x["City"])
train_x["City Group"] = cityGroupEncoded
train_x["Type"] = typeEncoded
train_x["City"] = cityEncoded

print(train_x)

def baseline_model():
	# create model
	model = Sequential()
	model.add(Dense(44, input_dim=44, kernel_initializer='normal', activation='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_squared_error', optimizer='adam')
	return model

# evaluate model with standardized dataset
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))
pipeline = Pipeline(estimators)
kfold = KFold(n_splits=10)

results = cross_val_score(pipeline, train_x, train_y, cv=kfold)
print("Standardized: %.2f (%.2f) MSE" % (results.mean(), results.std()))

def baseline_model2():
	# create model
	model = Sequential()
	model.add(Dense(44, input_dim=44, kernel_initializer='normal', activation='relu'))
	model.add(Dense(1, kernel_initializer='normal'))
	# Compile model
	model.compile(loss='mean_absolute_error', optimizer='adam')
	return model

# evaluate model with standardized dataset
estimators = []
estimators.append(('standardize', StandardScaler()))
estimators.append(('mlp', KerasRegressor(build_fn=baseline_model2, epochs=50, batch_size=5, verbose=0)))
pipeline = Pipeline(estimators)
kfold = KFold(n_splits=10)

results = cross_val_score(pipeline, train_x, train_y, cv=kfold)
print("Standardized: %.2f (%.2f) MAE" % (results.mean(), results.std()))

